{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 文本的正負向判斷，機器學習，情感分析。\n",
    "* NaiveBayesClassifier 分類器的應用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# machine learning 機器學習\n",
    "* 人們透過「經驗」來學習，機器透過「數據」來學習。\n",
    "* 「監督式學習」：訓練組( training data)，測試組 (test data), 目標文本(target data)。\n",
    "* 針對訓練組( training data) 訓練，找出一些分類的規則，接著再針對訓練組(test data)，看看依據這些分類規則進行分類，準確度有多高。如果滿意了，再針對目標文本(target data)進行分類預測。\n",
    "* 學習的演算法有多種，通常要利用類神經網絡來進行，蒐集的文件要足夠多，且恰當，分類的正確率即能提高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='d:/My python/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正向的文本，含標記，請注意格式, list of tuple, tuple 內 第一個元素為 文本，第二個為 標記\n",
    "pos_tweets = [('我 喜歡 車子', 'positive'),\n",
    "              ('我 太 高興','positive'),\n",
    "              ('他 太棒 了', 'positive'),\n",
    "              ('我 覺得 心情好', 'positive'),\n",
    "              ('音樂會 令人 感動', 'positive'),\n",
    "              ('我 的 這個 好 朋友。','positive')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 負向的文本，含標記，請注意格式, list of tuple, tuple 內 第一個元素為 文本，第二個為 標記\n",
    "neg_tweets = [('我 討厭 搭 公車', 'negative'),\n",
    "              ('他 太 可怕 了', 'negative'),\n",
    "              ('我 覺得 很 累', 'negative'),\n",
    "              ('我 不想 參加 這個 研討會', 'negative'),\n",
    "              ('我 不喜歡', 'negative'),\n",
    "              ('早上 是 競爭 對手', 'negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts=pos_tweets+neg_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams 函數，以多個字元作為分析單位\n",
    "def ngrams(input, min, max):\n",
    "    input = input.split(' ')\n",
    "    output = []\n",
    "    texts=''  \n",
    "    for c in range(min,max+1):\n",
    "        n=c\n",
    "        for i in range(len(input)-n+1):\n",
    "             texts=' '.join(input[i:i+n])\n",
    "             output.append(texts)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 化為文字袋，標記正向或反向。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "# 把測試組的所有資料叫進來，含字詞及情緒標記\n",
    "for (words, sentiment) in posts:\n",
    "    # 所有的字詞 與 情緒標記 ngram, min, max ##################\n",
    "    word_list=ngrams(words, 1,1) \n",
    "    \n",
    "    # 去除停用字 stopwords\n",
    "    #stopwords=['我', '很', '他', '早上', '的', '這個', '也', '一點']    \n",
    "    #word_list=[e for e  in word_list if e not in stopwords] \n",
    "    \n",
    "    # 字長控制\n",
    "    words_filtered = [e for e in word_list if len(e) >= 1]        \n",
    "    train_set.append((words_filtered, sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字袋標準格式，list of words, 含標記, tuple\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract features of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# 取得文本中所有的字詞 list，有重覆\n",
    "def get_words_in_tweets(train_set):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in train_set:\n",
    "        all_words.extend(words)\n",
    "    return all_words\n",
    "# 取得字詞列表，dictionary_key 不重復 \n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features\n",
    "# 字詞是否(True or False)在文件有被引用，dictionary\n",
    "def extract_features(train_set):\n",
    "    document_words = set(train_set)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 單一文本featurs與traning set 比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 字詞列表，不重復 dictionary_key\n",
    "get_words = get_words_in_tweets(train_set)\n",
    "get_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字詞列表， dictionary_key 不重復\n",
    "word_features = get_word_features(get_words_in_tweets(train_set))\n",
    "word_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字袋比對，是否有某個字詞。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 文字袋比對，是否有某個字詞。注意引數 extract_features, tweets　\n",
    "training = nltk.classify.apply_features(extract_features, train_set)\n",
    "\n",
    "# 訓練用資料共有十筆，依序顯示　training_set 內容\n",
    "for n in training:\n",
    "    print (n)\n",
    "    print ('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaiveBayesClassifier 分類器，各關鍵字出現與否，類別的機率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 找出潛在的規則\n",
    "classifier = nltk.NaiveBayesClassifier.train(training)\n",
    "# 列出最重要的 50 條規則\n",
    "print (classifier.show_most_informative_features(500))\n",
    "# 第一條規則：如果沒有 好 的話，負向的機率會是正向的 1.4 倍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 儲存 classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_classifier = open(path+\"data/naivebayes_test.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 呼叫 classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "classifier_f = open(path+\"data/naivebayes_test.pickle\", \"rb\")\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 簡單測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '我 很 累'\n",
    "print (classifier.classify(extract_features(test.split())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets =[('張三 是 我 的 壞 朋友','negative'),\n",
    "              ('我 不 喜歡 那個人','negative'),\n",
    "              ('那 首 歌 很 棒','positive'),\n",
    "              ('那 房子 令人 討厭','negative')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 針對 test set 進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('predict', 'real')\n",
    "print ('---------------')\n",
    "# 一筆筆逐一預測\n",
    "for t in test_tweets:\n",
    "    pred= classifier.classify(extract_features(t[0].split()))\n",
    "    print (pred, t[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算預測的正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes=0\n",
    "n=0\n",
    "for t in test_tweets:\n",
    "    pred= classifier.classify(extract_features(t[0].split()))\n",
    "    n+=1\n",
    "    if pred == t[1]:\n",
    "        yes+=1\n",
    "acc=yes/n\n",
    "print (acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Target Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目標測試，沒有情感標記，用我們的模型預測\n",
    "target_tweets =['他 的 歌 吵死 人 了',\n",
    "              '我 不 知道',  \n",
    "              '他 過去 紀錄 不 甚 好']\n",
    "for t in target_tweets:\n",
    "    print (classifier.classify(extract_features(t.split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 準確率不高，因為我們學習的資料不足。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多類別的預測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 多標籤分類問題而言，一個樣本可能同時屬於多個類別。如一個新聞屬於多個話題。這種情況下，因變數 y 需要使用一個矩陣表達出來。\n",
    "* 多類別分類指的是 y 的可能取值大於2，但是 y 所屬類別是唯一的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = [('我 喜歡 車子', 'A'),\n",
    "              ('早上 我 很 高興','A'),\n",
    "              ('他 真是 太棒 了', 'A'),\n",
    "              ('早上 我 覺得 心情 很 好', 'A'),\n",
    "              ('昨天 晚上 的 音樂會 令人 感動', 'A'),\n",
    "              ('他 是 我 最 要 好 的 朋友', 'A')]\n",
    "neg_tweets = [('我 討厭 搭 公車', 'B'),\n",
    "              ('這個 經歷 實在 太 可怕 了', 'B'),\n",
    "              ('早上 我 覺得 很 累', 'B'),\n",
    "              ('我 一點 也 不 期待 參加 這個 研討會', 'B'),\n",
    "              ('我 不喜歡 他', 'B'),\n",
    "              ('他 是 我 的 競爭 對手', 'B')]\n",
    "no_tweets =[('不 好 也 不 壞','C'),\n",
    "              ('實在 是 很 普通 啦','C'),\n",
    "              ('沒有 什麼 特別 的 感覺','C'),\n",
    "              ('我 不 知道','C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def get_test_group(total_test):\n",
    "    tweets = []\n",
    "    # 把測試組的所有資料叫進來，含字詞及情緒標記\n",
    "    for (words, sentiment) in total_test:\n",
    "        # 所有的字詞 與 情緒標記\n",
    "        word_list=ngrams(words, 1,1) \n",
    "        # 去除停用字 stopwords\n",
    "        stopwords=['我', '很', '他', '的', '也' ]   \n",
    "        word_list=[e for e  in word_list if e not in stopwords] \n",
    "\n",
    "        # 字長控制\n",
    "        words_filtered = [e for e in word_list if len(e) >= 1]        \n",
    "        tweets.append((words_filtered, sentiment))\n",
    "    return tweets   \n",
    "\n",
    "# 文本中所有的字詞 list\n",
    "def get_words_in_train(train_set):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in train_set:\n",
    "        all_words.extend(words)\n",
    "    return all_words\n",
    "# 字詞列表，不重復 dictionary_key\n",
    "def get_word_features(all_words):\n",
    "    wordlist = nltk.FreqDist(all_words)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features\n",
    "# 字詞是否在文件有被引用，dictionary\n",
    "def extract_features(train_set):\n",
    "    document_words = set(train_set)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test=pos_tweets + neg_tweets + no_tweets\n",
    "train_set=get_test_group(total_test)\n",
    "word_features = get_word_features(get_words_in_train(train_set))\n",
    "\n",
    "# 文字袋比對，注意引數 extract_features, tweets　\n",
    "training = nltk.classify.apply_features(extract_features,train_set)\n",
    "\n",
    "# 找出潛在的規則 classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(training)\n",
    "\n",
    "# 列出最重要的 50 條規則\n",
    "print (classifier.show_most_informative_features(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_tweets =[('張三 很 普普通通 啦','C'),\n",
    "              ('我 不喜歡 那個人','B'),\n",
    "              ('那 首 歌 太 吵 了','B'),\n",
    "              ('那 房子 令人 討厭','B')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes=0\n",
    "n=0\n",
    "print ('predict', 'real')\n",
    "print ('---------------')\n",
    "for t in Test_tweets:\n",
    "    pred= classifier.classify(extract_features(t[0].split()))\n",
    "    pred= classifier.classify(extract_features(t[0].split()))\n",
    "    print (pred, t[1])    \n",
    "    n+=1\n",
    "    if pred == t[1]:\n",
    "        yes+=1\n",
    "acc=yes/n\n",
    "print ('---------------')\n",
    "print (acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tweets =['他 確實 是 太棒 啦',\n",
    "              '他 真 的 很 討厭',  \n",
    "              '沒有 什麼 特別 的 感覺']\n",
    "\n",
    "for t in target_tweets:\n",
    "    print (classifier.classify(extract_features(t.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "# 用我們自己的資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料重整\n",
    "* 讀取自建的正向語料庫與負向語料庫，檔案頗大。檔案總管檢查。\n",
    "* 訓練自己的分類器。頗花時間。\n",
    "* 檢測正確率\n",
    "* 繁簡字體轉換：https://name.longwin.com.tw/twcn.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:怪怪~~這麼牛逼啊，身邊誰再買蒙牛，就罵誰SB！</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“”加錯位置了，抵制蒙牛“很多年”</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>一系列的醜聞表明蒙牛的管理層素質太差，公司治理混亂。消費者應拒絕購買其產品。</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>一直都在抵制與其抵制日貨，不如抵制蒙牛。</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>又是蒙牛 再也不能吃蒙牛了，蒙牛的任何產品都不買了</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>已經不喝牛奶了 已經不買蒙牛了 次奧2 次奧 還有人買蒙牛？！</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>已經不買蒙牛好幾個月了，堅持到丫倒閉</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>不愛喝蒙牛, 以後也不會喝.</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>支援中國乳業,支援蒙牛!</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>牛奶，永不喝蒙牛！@蒙牛乳業</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>牛逼 蒙牛牛逼</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>以後大家都別買不就行啦 蒙牛的公關太厲害了，得被潛了多少回了</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>出了多少事了，還買蒙牛伊利呢！只買地產三元！ 孫子不買蒙牛了</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>可悲呀！蒙牛還能吃嗎？哎！！！ 震驚了……</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>失敗！乳酪我不該買蒙牛的！我做的雞肉焗土豆泥失敗了！原料用錯不過唯一欣慰的是，土豆泥好吃</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>必須的，全新蒙牛 幸福啟航一起轉起來 來了，終於來了！</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>再也不喝蒙牛了</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>回覆 蒙牛客服對意見反饋及時，值得肯定。期待如你們所言，蒙牛成為中國最安全乳製品。</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>在蒙牛酸奶裡發現不明物！！！很噁心！！！</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>如果在香港這個品牌絕對倒閉+1 擴散。垃圾垃圾垃圾好牛逼 垃圾蒙牛！！！！</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>低階蒙牛 當然唔飲啦！ 不喝蒙牛很多年！</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>你小心了，蒙牛惹不起啊 http:t.cn/zjzDiup</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>你好，感謝對蒙牛產品的喜愛呦，我是蒙牛微客服，歡迎關注我。</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>你說，丁俊暉這幾年打球水平一般般，是不是因為喝多了蒙牛的緣故？</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>你還給父母買蒙牛？不孝啊 沒錯,現在還喝蒙牛的人不值得同情 還敢喝蒙牛？！是你自己的錯</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>坐等樓主這樣的被餓死或者被蒙牛之類的毒死</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>我投給了&amp;quot;王小山抵制後不喝蒙牛&amp;quot; 這個選項。</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>我來幫你一把 好牛逼 垃圾蒙牛！！！！</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>我覺得我今天之所以一直拉肚子，就是因為你早上給我的蒙牛以後不要喝蒙牛！拉肚子晚上還要喝，真是造孽</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>房間地毯還有沙發都很髒,床的彈簧都要出來了,很不舒服,以後不會再住了</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6340</th>\n",
       "      <td>顯示卡，CPU對於主流遊戲來說已經夠用了；電腦整體做工也還算優良，散熱挺好的。</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>顯示卡不錯，LED屏，總體感覺不錯。京東送貨正的挺快啊。。。24小時不到就送到了。</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6342</th>\n",
       "      <td>顯示卡相當不錯。大型3D網遊也都能承受，散熱也做得想當不錯。 做圖得效果不錯、渲染很漂亮、、</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6343</th>\n",
       "      <td>顯示卡真是不行，看rmvb電影時如果有其他操作 畫面也會卡一下，不過畢竟是上網本，可以容忍</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6344</th>\n",
       "      <td>顯示卡強大,基本跑遊戲都跑得起來,看起來也很爽,和桌上型電腦差不多了..</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6345</th>\n",
       "      <td>顯示卡跑遊戲還是差了點，1g記憶體執行VISTA還是差了點,螢幕視角還是差了點</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6346</th>\n",
       "      <td>顯示卡還不錯了~螢幕也還可以，拿來玩遊戲這個價格裡找不到可以抗衡的對手了</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6347</th>\n",
       "      <td>顯示卡驅動不好裝，網上找了好久。 最後終於搞定。我裝的是VISTA Ultimate SP1 .</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6348</th>\n",
       "      <td>顯示卡驅動居然識別成G96，裝新版驅動才識別成110M，用暴風看，有點卡，不知道咋回事！</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6349</th>\n",
       "      <td>顯示屏十分清晰！拍照時，啟動速度還可以！可以手寫輸入文字！</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6350</th>\n",
       "      <td>顯示屏不錯，音樂播放很好，電池是索愛的優點。</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351</th>\n",
       "      <td>顯示屏不錯，鍵盤也很好。而且右邊有小鍵盤，輸入數字方便快捷多了。</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6352</th>\n",
       "      <td>顯示屏效果不錯。防滑邊框新穎。拍照功能還可以。支援自編鈴聲。</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>顯示屏塑料外殼邊緣有損壞，是不是因為無店鋪銷售，所以提供的是等外品啊！</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6354</th>\n",
       "      <td>顯示效果很好！支援GPERS/WAP上網16和玄鈴聲11W畫素可儲存瀏覽網頁中的圖片！</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355</th>\n",
       "      <td>驚奇的發現，原來我們學校給孩子們喝的都是蒙牛，罪過，罪過！</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>體積小,方便攜帶.各效能平衡在同價位的產品中算得上是佼佼者.流暢執行VISTA沒有問題.</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>體積小，翻蓋，彩屏，16和玄的鈴聲，雙電雙衝，而且最主要的是價錢不貴，很適合女孩子使用的。</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>體積很小，外觀也很大方。</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>體積輕巧。做工精細。價格低廉。</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>讓人不會用,資料線是擺設連線就充電,真是活見鬼!</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6361</th>\n",
       "      <td>讓我失望的一本小說，內容牽強，故作懸念。</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>讓我最不爽的是沒有ＸＰ的驅動盤，我上官網下載花了我一下午時間！</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363</th>\n",
       "      <td>讓我給轉亂了！ 都轉 是轉蒙牛倒閉呢還是轉吃黑巧克力呢？轉到蒙牛倒閉！！ 說蒙牛呢 快倒閉吧！</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6364</th>\n",
       "      <td>讓抵制日貨的蠢貨們喝蒙牛伊利，吃地溝油去吧！</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6365</th>\n",
       "      <td>讓蒙牛去死吧</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6366</th>\n",
       "      <td>蠻好用的。不錯</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6367</th>\n",
       "      <td>鬱悶 果然是低端的產品 送來的第一臺是沒有tab鍵的 換貨的第二臺是有外觀瑕疵的</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6368</th>\n",
       "      <td>鬱悶 買了3本書 沒有一本完好無缺的 不知道怎麼運貨的 全劃壞了</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6369</th>\n",
       "      <td>鬱悶,幾張紙的故事偏要用來做書名,簡直就是忽悠人</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6370 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text tag\n",
       "0                             :怪怪~~這麼牛逼啊，身邊誰再買蒙牛，就罵誰SB！   N\n",
       "1                                     “”加錯位置了，抵制蒙牛“很多年”   N\n",
       "2                一系列的醜聞表明蒙牛的管理層素質太差，公司治理混亂。消費者應拒絕購買其產品。   N\n",
       "3                                  一直都在抵制與其抵制日貨，不如抵制蒙牛。   N\n",
       "4                             又是蒙牛 再也不能吃蒙牛了，蒙牛的任何產品都不買了   N\n",
       "5                       已經不喝牛奶了 已經不買蒙牛了 次奧2 次奧 還有人買蒙牛？！   N\n",
       "6                                    已經不買蒙牛好幾個月了，堅持到丫倒閉   N\n",
       "7                                        不愛喝蒙牛, 以後也不會喝.   N\n",
       "8                                          支援中國乳業,支援蒙牛!   P\n",
       "9                                        牛奶，永不喝蒙牛！@蒙牛乳業   N\n",
       "10                                              牛逼 蒙牛牛逼   N\n",
       "11                       以後大家都別買不就行啦 蒙牛的公關太厲害了，得被潛了多少回了   P\n",
       "12                       出了多少事了，還買蒙牛伊利呢！只買地產三元！ 孫子不買蒙牛了   N\n",
       "13                                可悲呀！蒙牛還能吃嗎？哎！！！ 震驚了……   N\n",
       "14         失敗！乳酪我不該買蒙牛的！我做的雞肉焗土豆泥失敗了！原料用錯不過唯一欣慰的是，土豆泥好吃   N\n",
       "15                          必須的，全新蒙牛 幸福啟航一起轉起來 來了，終於來了！   P\n",
       "16                                              再也不喝蒙牛了   N\n",
       "17            回覆 蒙牛客服對意見反饋及時，值得肯定。期待如你們所言，蒙牛成為中國最安全乳製品。   P\n",
       "18                                 在蒙牛酸奶裡發現不明物！！！很噁心！！！   N\n",
       "19                如果在香港這個品牌絕對倒閉+1 擴散。垃圾垃圾垃圾好牛逼 垃圾蒙牛！！！！   N\n",
       "20                                 低階蒙牛 當然唔飲啦！ 不喝蒙牛很多年！   N\n",
       "21                        你小心了，蒙牛惹不起啊 http:t.cn/zjzDiup   N\n",
       "22                        你好，感謝對蒙牛產品的喜愛呦，我是蒙牛微客服，歡迎關注我。   P\n",
       "23                      你說，丁俊暉這幾年打球水平一般般，是不是因為喝多了蒙牛的緣故？   N\n",
       "24          你還給父母買蒙牛？不孝啊 沒錯,現在還喝蒙牛的人不值得同情 還敢喝蒙牛？！是你自己的錯   N\n",
       "25                                 坐等樓主這樣的被餓死或者被蒙牛之類的毒死   N\n",
       "26                     我投給了&quot;王小山抵制後不喝蒙牛&quot; 這個選項。   N\n",
       "27                                  我來幫你一把 好牛逼 垃圾蒙牛！！！！   N\n",
       "28     我覺得我今天之所以一直拉肚子，就是因為你早上給我的蒙牛以後不要喝蒙牛！拉肚子晚上還要喝，真是造孽   N\n",
       "29                   房間地毯還有沙發都很髒,床的彈簧都要出來了,很不舒服,以後不會再住了   N\n",
       "...                                                 ...  ..\n",
       "6340            顯示卡，CPU對於主流遊戲來說已經夠用了；電腦整體做工也還算優良，散熱挺好的。   P\n",
       "6341          顯示卡不錯，LED屏，總體感覺不錯。京東送貨正的挺快啊。。。24小時不到就送到了。   P\n",
       "6342     顯示卡相當不錯。大型3D網遊也都能承受，散熱也做得想當不錯。 做圖得效果不錯、渲染很漂亮、、   P\n",
       "6343      顯示卡真是不行，看rmvb電影時如果有其他操作 畫面也會卡一下，不過畢竟是上網本，可以容忍   N\n",
       "6344               顯示卡強大,基本跑遊戲都跑得起來,看起來也很爽,和桌上型電腦差不多了..   P\n",
       "6345            顯示卡跑遊戲還是差了點，1g記憶體執行VISTA還是差了點,螢幕視角還是差了點   N\n",
       "6346               顯示卡還不錯了~螢幕也還可以，拿來玩遊戲這個價格裡找不到可以抗衡的對手了   P\n",
       "6347   顯示卡驅動不好裝，網上找了好久。 最後終於搞定。我裝的是VISTA Ultimate SP1 .   N\n",
       "6348       顯示卡驅動居然識別成G96，裝新版驅動才識別成110M，用暴風看，有點卡，不知道咋回事！   N\n",
       "6349                      顯示屏十分清晰！拍照時，啟動速度還可以！可以手寫輸入文字！   P\n",
       "6350                             顯示屏不錯，音樂播放很好，電池是索愛的優點。   P\n",
       "6351                   顯示屏不錯，鍵盤也很好。而且右邊有小鍵盤，輸入數字方便快捷多了。   P\n",
       "6352                     顯示屏效果不錯。防滑邊框新穎。拍照功能還可以。支援自編鈴聲。   P\n",
       "6353                顯示屏塑料外殼邊緣有損壞，是不是因為無店鋪銷售，所以提供的是等外品啊！   N\n",
       "6354        顯示效果很好！支援GPERS/WAP上網16和玄鈴聲11W畫素可儲存瀏覽網頁中的圖片！   P\n",
       "6355                      驚奇的發現，原來我們學校給孩子們喝的都是蒙牛，罪過，罪過！   N\n",
       "6356       體積小,方便攜帶.各效能平衡在同價位的產品中算得上是佼佼者.流暢執行VISTA沒有問題.   P\n",
       "6357      體積小，翻蓋，彩屏，16和玄的鈴聲，雙電雙衝，而且最主要的是價錢不貴，很適合女孩子使用的。   P\n",
       "6358                                       體積很小，外觀也很大方。   P\n",
       "6359                                    體積輕巧。做工精細。價格低廉。   P\n",
       "6360                           讓人不會用,資料線是擺設連線就充電,真是活見鬼!   N\n",
       "6361                               讓我失望的一本小說，內容牽強，故作懸念。   N\n",
       "6362                    讓我最不爽的是沒有ＸＰ的驅動盤，我上官網下載花了我一下午時間！   N\n",
       "6363    讓我給轉亂了！ 都轉 是轉蒙牛倒閉呢還是轉吃黑巧克力呢？轉到蒙牛倒閉！！ 說蒙牛呢 快倒閉吧！   N\n",
       "6364                             讓抵制日貨的蠢貨們喝蒙牛伊利，吃地溝油去吧！   N\n",
       "6365                                             讓蒙牛去死吧   N\n",
       "6366                                            蠻好用的。不錯   P\n",
       "6367           鬱悶 果然是低端的產品 送來的第一臺是沒有tab鍵的 換貨的第二臺是有外觀瑕疵的   N\n",
       "6368                   鬱悶 買了3本書 沒有一本完好無缺的 不知道怎麼運貨的 全劃壞了   N\n",
       "6369                           鬱悶,幾張紙的故事偏要用來做書名,簡直就是忽悠人   N\n",
       "\n",
       "[6370 rows x 2 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################################\n",
    "import pandas as pd\n",
    "path='d:/My python/'\n",
    "df=pd.read_excel(path+\"corpus/情緒文本P_N.xlsx\",index_col=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pos_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3036"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos=df[df.tag==\"P\"]\n",
    "len(df_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 去特殊符號(t):\n",
    "    import re\n",
    "    # 特殊符號可以自己增補\n",
    "    t = re.sub(r\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",t)\n",
    "    t = re.sub(r'[-，+、@,？⊂・ω{}●►❖★！!：\\\\/(=)…（）『』%《》$;；」:?=<>\"／.&#\"「_【】]', \"\",t)    \n",
    "    # 去除數字\n",
    "    t = re.sub(r\"[0123456789]\",\"\",t)    \n",
    "    # 去除英文  \n",
    "    t = re.sub(r\"[a-zA-Z]\",\"\",t)      \n",
    "    return t  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from d:\\My python\\corpus\\dict.txt.big.txt ...\n",
      "Loading model from cache C:\\Users\\terry\\AppData\\Local\\Temp\\jieba.ubf87c04fd9101ff99585dd1caa415b1f.cache\n",
      "Loading model cost 1.004 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 中文斷字，並刪除無意義的符號\n",
    "import re\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from optparse import OptionParser\n",
    "\n",
    "# 設定斷詞字典\n",
    "jieba.set_dictionary(path+\"corpus/dict.txt.big.txt\")    \n",
    "   \n",
    "# 增加新詞，字典可以隨時叫出修改， 增添新的詞彙。 \n",
    "jieba.load_userdict(path+ \"corpus/userdict.txt\")   \n",
    "\n",
    "seg_list=[]\n",
    "for t in df.text:\n",
    "    t= 去特殊符號(t)\n",
    "    # 結巴分詞，引數為 string。\n",
    "    result = jieba.cut(t)\n",
    "\n",
    "    # 讀取中文斷詞結果，存為 string，中間以空白隔開\n",
    "    seg_string=''\n",
    "    for word in result:\n",
    "        seg_string= seg_string + word+' '\n",
    "\n",
    "    # string 轉為 list\n",
    "    seg_list.append(seg_string)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:怪怪~~這麼牛逼啊，身邊誰再買蒙牛，就罵誰SB！</td>\n",
       "      <td>N</td>\n",
       "      <td>怪怪 這麼 牛 逼 啊 身邊 誰 再 買 蒙牛 就 罵誰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“”加錯位置了，抵制蒙牛“很多年”</td>\n",
       "      <td>N</td>\n",
       "      <td>“ ” 加錯 位置 了 抵制 蒙牛 “ 很多年 ”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>一系列的醜聞表明蒙牛的管理層素質太差，公司治理混亂。消費者應拒絕購買其產品。</td>\n",
       "      <td>N</td>\n",
       "      <td>一系列 的 醜聞 表明 蒙牛 的 管理層 素質 太差 公司 治理 混亂 消費者 應 拒絕 購...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>一直都在抵制與其抵制日貨，不如抵制蒙牛。</td>\n",
       "      <td>N</td>\n",
       "      <td>一直 都 在 抵制 與其 抵制 日貨 不如 抵制 蒙牛</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>又是蒙牛 再也不能吃蒙牛了，蒙牛的任何產品都不買了</td>\n",
       "      <td>N</td>\n",
       "      <td>又 是 蒙牛 再也不能 吃 蒙牛 了 蒙牛 的 任何 產品 都 不 買 了</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text tag  \\\n",
       "0                :怪怪~~這麼牛逼啊，身邊誰再買蒙牛，就罵誰SB！   N   \n",
       "1                        “”加錯位置了，抵制蒙牛“很多年”   N   \n",
       "2   一系列的醜聞表明蒙牛的管理層素質太差，公司治理混亂。消費者應拒絕購買其產品。   N   \n",
       "3                     一直都在抵制與其抵制日貨，不如抵制蒙牛。   N   \n",
       "4                又是蒙牛 再也不能吃蒙牛了，蒙牛的任何產品都不買了   N   \n",
       "\n",
       "                                               token  \n",
       "0                      怪怪 這麼 牛 逼 啊 身邊 誰 再 買 蒙牛 就 罵誰   \n",
       "1                         “ ” 加錯 位置 了 抵制 蒙牛 “ 很多年 ”   \n",
       "2  一系列 的 醜聞 表明 蒙牛 的 管理層 素質 太差 公司 治理 混亂 消費者 應 拒絕 購...  \n",
       "3                       一直 都 在 抵制 與其 抵制 日貨 不如 抵制 蒙牛   \n",
       "4             又 是 蒙牛 再也不能 吃 蒙牛 了 蒙牛 的 任何 產品 都 不 買 了   "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token']=seg_list\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加註情感標記\n",
    "pos_set=[]\n",
    "neg_set=[]\n",
    "for d in range(len(df.token)):\n",
    "    if df.iloc[d]['tag']==\"P\":\n",
    "        pos_set.append((df.iloc[d]['token'],'positive'))\n",
    "    else:\n",
    "        neg_set.append((df.iloc[d]['token'],'negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('支援 中國 乳業 支援 蒙牛 ', 'positive'),\n",
       " ('以後 大家 都 別 買 不 就 行 啦 蒙牛 的 公關 太 厲害 了 得 被 潛 了 多少 回 了 ', 'positive'),\n",
       " ('必須 的 全新 蒙牛 幸福 啟航 一起 轉起 來來 了 終於 來 了 ', 'positive'),\n",
       " ('回覆 蒙牛 客服 對 意見反饋 及時 值得 肯定 期待 如 你們 所 言 蒙牛 成為 中國 最 安全 乳製品 ', 'positive'),\n",
       " ('你好 感謝 對 蒙牛 產品 的 喜愛 呦 我 是 蒙牛 微 客服 歡迎 關注 我 ', 'positive'),\n",
       " ('所以 蒙牛 的 奶要 多 給點 信心 要 多 喝 ', 'positive'),\n",
       " ('喜歡 喝 蒙牛 不 ', 'positive'),\n",
       " ('絕對 是 蒙牛 的 老 酸奶 比如 實 好吃 ', 'positive'),\n",
       " ('想 不想 啊 這個 是 現在 我 的 最愛 啊 我 覺得 蒙牛 好 一點 啊 ', 'positive'),\n",
       " ('蒙牛 鎮的 很 牛 ', 'positive')]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_set[0:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('怪怪 這麼 牛 逼 啊 身邊 誰 再 買 蒙牛 就 罵誰 ', 'negative'),\n",
       " ('“ ” 加錯 位置 了 抵制 蒙牛 “ 很多年 ” ', 'negative'),\n",
       " ('一系列 的 醜聞 表明 蒙牛 的 管理層 素質 太差 公司 治理 混亂 消費者 應 拒絕 購買 其 產品 ', 'negative'),\n",
       " ('一直 都 在 抵制 與其 抵制 日貨 不如 抵制 蒙牛 ', 'negative'),\n",
       " ('又 是 蒙牛 再也不能 吃 蒙牛 了 蒙牛 的 任何 產品 都 不 買 了 ', 'negative'),\n",
       " ('已經 不 喝牛奶 了 已經 不買 蒙牛 了 次 奧次 奧 還有 人買 蒙牛 ', 'negative'),\n",
       " ('已經 不買 蒙牛 好幾個 月 了 堅持 到 丫 倒閉 ', 'negative'),\n",
       " ('不 愛喝 蒙牛 以後 也 不會 喝 ', 'negative'),\n",
       " ('牛奶 永不 喝 蒙牛 蒙牛 乳業 ', 'negative'),\n",
       " ('牛 逼 蒙牛 牛 逼 ', 'negative')]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_set[0:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開始訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams 函數，以多個字元為分析單位\n",
    "def ngrams(input, min, max):\n",
    "    input = input.split(' ')\n",
    "    output = []\n",
    "    texts=''  \n",
    "    for c in range(min,max+1):\n",
    "        n=c\n",
    "        for i in range(len(input)-n+1):\n",
    "            texts=' '.join(input[i:i+n])\n",
    "            output.append(texts)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_set, 訓練資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "# 把測試組的所有資料叫進來，含字詞及情緒標記 #######\n",
    "for (words, sentiment) in pos_set + neg_set:\n",
    "    # 所有的字詞 與 情緒標記\n",
    "    word_list=ngrams(words, 1,1) \n",
    "    \n",
    "    # 去除停用字 stopwords\n",
    "    stopwords=['我', '很', '他', '的', '也' ,\"內容\"]   \n",
    "    word_list=[e for e  in word_list if e not in stopwords] \n",
    "   \n",
    "    # 字長控制\n",
    "    words_filtered = [e for e in word_list if len(e) >= 1]        \n",
    "    train_set.append((words_filtered, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# 取得文本中所有的字詞 list，有重覆\n",
    "def get_words_in_train(train_set):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in train_set:\n",
    "        all_words.extend(words)\n",
    "    return all_words\n",
    "# 取得字詞列表，不重復 dictionary_key\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features\n",
    "# 字詞是否(True or False)在文件有被引用，dictionary\n",
    "def extract_features(train_set):\n",
    "    document_words = set(train_set)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類器，要花時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字詞列表， dictionary_key 不重復\n",
    "word_features = get_word_features(get_words_in_train(train_set))\n",
    "\n",
    "# 文字袋比對，每一筆資料，字詞的有無，注意引數 extract_features, tweets　\n",
    "training = nltk.classify.apply_features(extract_features, train_set)\n",
    "\n",
    "# 這要花時間 ############\n",
    "# 找出潛在的規則\n",
    "classifier = nltk.NaiveBayesClassifier.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            contains(時尚) = True           positi : negati =     42.1 : 1.0\n",
      "            contains(宕機) = True           negati : positi =     34.3 : 1.0\n",
      "            contains(鬱悶) = True           negati : positi =     28.8 : 1.0\n",
      "            contains(小巧) = True           positi : negati =     28.8 : 1.0\n",
      "            contains(抵制) = True           negati : positi =     24.6 : 1.0\n",
      "            contains(根本) = True           negati : positi =     24.0 : 1.0\n",
      "            contains(漂亮) = True           positi : negati =     22.9 : 1.0\n",
      "            contains(垃圾) = True           negati : positi =     21.7 : 1.0\n",
      "            contains(夠用) = True           positi : negati =     21.6 : 1.0\n",
      "            contains(很差) = True           negati : positi =     20.9 : 1.0\n",
      "            contains(正品) = True           positi : negati =     20.9 : 1.0\n",
      "            contains(遠離) = True           negati : positi =     20.3 : 1.0\n",
      "            contains(感謝) = True           positi : negati =     20.1 : 1.0\n",
      "            contains(光明) = True           positi : negati =     19.4 : 1.0\n",
      "            contains(挺快) = True           positi : negati =     18.7 : 1.0\n",
      "          contains(價格便宜) = True           positi : negati =     17.9 : 1.0\n",
      "            contains(好吃) = True           positi : negati =     17.2 : 1.0\n",
      "            contains(一款) = True           positi : negati =     17.2 : 1.0\n",
      "            contains(足夠) = True           positi : negati =     16.5 : 1.0\n",
      "            contains(幸福) = True           positi : negati =     16.5 : 1.0\n",
      "            contains(實惠) = True           positi : negati =     16.2 : 1.0\n",
      "            contains(價效) = True           positi : negati =     16.0 : 1.0\n",
      "            contains(超值) = True           positi : negati =     15.7 : 1.0\n",
      "            contains(香蕉) = True           positi : negati =     15.7 : 1.0\n",
      "            contains(兒子) = True           negati : positi =     14.9 : 1.0\n",
      "            contains(也好) = True           positi : negati =     14.7 : 1.0\n",
      "            contains(強大) = True           positi : negati =     14.3 : 1.0\n",
      "            contains(流暢) = True           positi : negati =     14.3 : 1.0\n",
      "            contains(太差) = True           negati : positi =     14.3 : 1.0\n",
      "            contains(不錯) = True           positi : negati =     13.9 : 1.0\n",
      "            contains(外觀) = True           positi : negati =     13.0 : 1.0\n",
      "            contains(不如) = True           negati : positi =     12.9 : 1.0\n",
      "            contains(冠益) = True           positi : negati =     12.8 : 1.0\n",
      "            contains(適中) = True           positi : negati =     12.8 : 1.0\n",
      "             contains(乳) = True           positi : negati =     12.8 : 1.0\n",
      "            contains(再也) = True           negati : positi =     12.6 : 1.0\n",
      "            contains(失望) = True           negati : positi =     12.4 : 1.0\n",
      "             contains(歲) = True           negati : positi =     11.8 : 1.0\n",
      "             contains(寫) = True           negati : positi =     11.6 : 1.0\n",
      "             contains(逼) = True           negati : positi =     11.5 : 1.0\n",
      "          contains(總的來說) = True           positi : negati =     11.3 : 1.0\n",
      "             contains(粒) = True           positi : negati =     11.3 : 1.0\n",
      "            contains(很快) = True           positi : negati =     11.3 : 1.0\n",
      "            contains(嚴重) = True           negati : positi =     11.2 : 1.0\n",
      "            contains(堅決) = True           negati : positi =     11.2 : 1.0\n",
      "            contains(賣家) = True           positi : negati =     11.2 : 1.0\n",
      "            contains(齊全) = True           positi : negati =     10.8 : 1.0\n",
      "           contains(招待所) = True           negati : positi =     10.6 : 1.0\n",
      "            contains(太慢) = True           negati : positi =     10.6 : 1.0\n",
      "            contains(寶貝) = True           positi : negati =     10.3 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 列出最重要的 50 條規則\n",
    "print (classifier.show_most_informative_features(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_classifier = open(path+\"data/naivebayes_senti.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classifier\n",
    "import pickle\n",
    "classifier_f = open(path+\"data/naivebayes_senti.pickle\", \"rb\")\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## test_set 測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set =[('作者列舉的方法太麻煩，配料也不好找。不是太實用。','negative'),\n",
    "           ('那房子令人討厭','negative'),\n",
    "           ('作者有一種專業的謹慎，全書結構簡單，但内容詳實。', 'positive'),\n",
    "           ('最大的缺陷是容易養成中文式英語','negative'),\n",
    "           ('那首歌太吵了','negative'),           \n",
    "           ('早上我覺得心情很好', 'positive'),\n",
    "           ('昨天晚上的音樂會令人感動', 'positive')\n",
    "           ]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from d:\\My python\\corpus\\dict.txt.big.txt ...\n",
      "Loading model from cache C:\\Users\\terry\\AppData\\Local\\Temp\\jieba.ubf87c04fd9101ff99585dd1caa415b1f.cache\n",
      "Loading model cost 1.006 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 中文斷字，並刪除無意義的符號\n",
    "import re\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from optparse import OptionParser\n",
    "\n",
    "# 設定斷詞字典\n",
    "jieba.set_dictionary(path+\"corpus/dict.txt.big.txt\")    \n",
    "   \n",
    "# 增加新詞，字典可以隨時叫出修改， 增添新的詞彙。 \n",
    "jieba.load_userdict(path+ \"corpus/userdict.txt\")   \n",
    "\n",
    "test_token=[]\n",
    "for n in range(len(test_set)):\n",
    "    result = jieba.cut(test_set[n][0])\n",
    "    # 結巴分詞，引數為 string。\n",
    "    texts=''\n",
    "    for t in result:\n",
    "       texts=texts+ ' '+ t\n",
    "    test_token.append(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 作者 列舉 的 方法 太 麻煩 ， 配料 也 不好 找 。 不是 太 實用 。',\n",
       " ' 那 房子 令人討厭',\n",
       " ' 作者 有 一種 專業 的 謹慎 ， 全書 結構 簡單 ， 但 内容 詳實 。',\n",
       " ' 最大 的 缺陷 是 容易 養成 中文 式 英語',\n",
       " ' 那首歌 太吵 了',\n",
       " ' 早上 我 覺得 心情 很 好',\n",
       " ' 昨天晚上 的 音樂會 令人感動']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative negative\n",
      "positive negative\n",
      "negative positive\n",
      "negative negative\n",
      "negative negative\n",
      "positive positive\n",
      "positive positive\n",
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# 正確率計算\n",
    "yes=0\n",
    "for t in range(len(test_token)):\n",
    "    pred= classifier.classify(extract_features(test_token[t].split()))\n",
    "    n+=1\n",
    "    print (pred, test_set[t][1])    \n",
    "    \n",
    "    if pred == test_set[t][1]:\n",
    "        yes+=1\n",
    "acc=yes/len(test_set)\n",
    "print (acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target 標的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "negative\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "target =['他 確實 是 普普通通 啦',\n",
    "         '我 真 的 不 知道',  \n",
    "         '沒有 什麼 特別 的 感覺']\n",
    "\n",
    "for t in target:\n",
    "    print (classifier.classify(extract_features(t.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 作業\n",
    "* 建置自己的訓練組，正向語料與負向語料。正負向語料各一百則。\n",
    "* 語料為任選一段文字，加情緒註記，'negative','positive'。\n",
    "* 存成 pickle 檔，檔名為 pos_set.pickle, neg_set.pickl。交作業時一起交。\n",
    "* 製作分類器。\n",
    "* 測試正確度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
